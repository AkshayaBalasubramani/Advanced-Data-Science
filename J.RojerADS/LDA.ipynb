{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecccca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9895d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets='Train_QuantumTunnel_Tweets.csv'\n",
    "tweets=pd.read_csv(tweets,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee5c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions_hashtags_urls(tw):\n",
    "    mnt = re.compile(\"@\\w+(?:[-’]\\w+)*|\")\n",
    "    hash = re.compile('#\\w+(?:[-]\\w+)*')\n",
    "    urls = re.compile('http\\S+')\n",
    "    mention = \" \".join(mnt.findall(tw))\n",
    "    hashtag = \" \".join(hash.findall(tw))\n",
    "    link = \" \".join(urls.findall(tw))\n",
    "    return mention, hashtag, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2506eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Mentions'],tweets['Hashtags'],tweets['URLs']=zip(*tweets['Tweet'].map(mentions_hashtags_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14fcd745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mentions</th>\n",
       "      <th>URLs</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>@R_Trotta                                     ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>...</td>\n",
       "      <td>https://t.co/no4Usx6djV</td>\n",
       "      <td>#maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>...</td>\n",
       "      <td>http://t.co/fW7pSgTWGj</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mentions  \\\n",
       "321  @R_Trotta                                     ...   \n",
       "322                                                ...   \n",
       "323                                                ...   \n",
       "\n",
       "                        URLs Hashtags  \n",
       "321                                    \n",
       "322  https://t.co/no4Usx6djV   #maths  \n",
       "323   http://t.co/fW7pSgTWGj           "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[['Mentions','URLs','Hashtags']].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32688bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "porter=nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a521e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "stop_words.extend([\"i've\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b43060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91821\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448db6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tw_preprocess(tw):\n",
    "    tw = tw.lower()\n",
    "    tw = re.sub(\"@\\w+(?:[-’]\\w+)*\",\"\", tw)\n",
    "    tw = re.sub(r\"\\S*\\d\\S*\",\"\", tw)\n",
    "    tw = re.sub(\"http\\S+\",\"\", tw)\n",
    "    tw = re.sub(\"[#|']\", \"\", tw)\n",
    "    tokens = TweetTokenizer().tokenize(tw)\n",
    "    tokens = [t for t in tokens if t not in\n",
    "    stop_words]\n",
    "    tokens = [porter.stem(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t not in\n",
    "    string.punctuation]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac38f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Processed_Tweet\"]=tweets[\"Tweet\"].apply(tw_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1566d4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319                                   perhap peopl level\n",
       "320    yay connect automat eduroam univers michigan g...\n",
       "321    true mean would cinema arriv late also paid en...\n",
       "322                 report card famou mathematician math\n",
       "323         princeton guid linear model logist regress r\n",
       "Name: Processed_Tweet, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"Processed_Tweet\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "561c359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "no_features=1000\n",
    "\n",
    "vectoriser=CountVectorizer(min_df=2,max_features=no_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0f72b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\91821\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\91821\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\91821\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\91821\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\91821\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a63494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_vectorizer=vectoriser.fit_transform(tweets[\"Processed_Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b4e5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_vectorizer_names=vectoriser.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "677ab14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actual' 'ai' 'algorithm' 'alien' 'amaz']\n"
     ]
    }
   ],
   "source": [
    "print(tw_vectorizer_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42285337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0ef5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = range(3, 8)\n",
    "search_params = {\"n_components\": n_components,\n",
    "\"learning_decay\": [0.6, 0.8, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9ca50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(\n",
    "max_iter=10,\n",
    "learning_method=\"online\",\n",
    "random_state=0,\n",
    "evaluate_every=-1,\n",
    "learning_offset=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f2c630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "model = GridSearchCV(lda,param_grid=search_params,cv=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f83d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tw_vectorizer) \n",
    "best_lda_model = model.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d0cfc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model’s Params:  {'learning_decay': 1.0, 'n_components': 3}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model’s Params: \",model.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b3a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
